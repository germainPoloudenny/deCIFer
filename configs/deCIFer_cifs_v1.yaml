# CONFIG YAML

out_dir: 'runs/deCIFer_cifs_v1_model' 
eval_interval: 250  # how often to evaluate against the validation set
eval_iters_train: 200 # how many iterations for evaluating training loss
eval_iters_val: 200 # how many iterations for evaluating validation loss
log_interval: 1  # how often to print to the console (1 = every iteration)
init_from: 'resume' # intialise from ["scratch", "resume"]

device: 'cuda' # device
dtype: 'float16' # device dtype
distributed: true # enable DistributedDataParallel
dist_backend: 'nccl' # backend used for torch.distributed

always_save_checkpoint: True # always save checkpoint
use_tensorboard: True
tensorboard_log_dir: 'runs/deCIFer_cifs_v1_model/tensorboard'

validate: True # validate with a validation set

dataset: '../crystallography/data/structures/cifs_v1'
batch_size: 128 # batch size
block_size: 3076 # context window

n_layer: 8 # n_layers
n_head: 8 # n_head
n_embd: 512 # n_embed
dropout: 0.0 # dropout

learning_rate: 1e-3 # learning rate (AdamW)
gradient_accumulation_steps: 40  # used to simulate larger batch sizes
max_iters: 50_000 # max number of epochs
lr_decay_iters: 50_000 # learning reate decay
min_lr: 1e-6 # min learning rate
beta2: 0.99 # beta2

warmup_iters: 100 # warmup iterations

early_stopping_patience: 100 # early stopping patience (epochs)

fwhm_range_min: 0.001 # min. for the FWHM range
fwhm_range_max: 0.10 # max. for the FWHM range
noise_range_min: 0.001 # min. for the uniform sampling of std. for additive noise
noise_range_max: 0.05 # max. for the uniform sampling of std. for additive noise

condition: True # Enable conditioning (deCIFer)
precompute_conditioning: True
precompute_conditioning_batch_size: 16
boundary_masking: False # Boundary masking no longer needed when batches avoid cross-CIF windows.

dataset_fraction: 0.1
