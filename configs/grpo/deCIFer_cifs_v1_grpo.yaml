# GRPO fine-tuning configuration for the deCIFer CIFs v1 model.
#
# This file intentionally contains only the options recognised by GRPOConfig.
# It can be used as-is with bin/train_grpo.py or serve as a template for
# custom reinforcement-learning runs.
out_dir: runs/grpo/deCIFer_cifs_v1

# Dataset and checkpoints
# -----------------------
dataset: '../crystallography/data/structures/cifs_v1'
init_checkpoint: runs/deCIFer_cifs_v1_model/ckpt_eval.pt
reference_checkpoint: null
dataset_split: train

# Rollout generation
# ------------------
batch_size: 32
group_size: 4
temperature: 1.0
top_k: null
add_composition: true
add_spacegroup: false
conditioning_kwargs:
  qmin: 0.0
  qmax: 10.0
  qstep: 0.01
  fwhm_range: [0.001, 0.05]
  eta_range: [0.5, 0.5]
  noise_range: [0.001, 0.05]
  intensity_scale_range: [1.0, 1.0]
  mask_prob: 0.0
precompute_conditioning: true
precompute_conditioning_batch_size: 256
conditioning_cache_dir: runs/deCIFer_cifs_v1_model/conditioning_cache

# Optimisation hyperparameters
# ----------------------------
learning_rate: 5.0e-06
betas: [0.9, 0.95]
weight_decay: 0.1
grad_clip: 1.0
mini_batch_size: null
update_epochs: 4
clip_range: 0.2
kl_coef: 0.02
target_kl: 0.1

# Reward shaping
# --------------
reward_scale: 1.0
invalid_reward: -5.0
fallback_reward_scale: 1.0
normalize_advantages: true

# Training schedule
# -----------------
max_iterations: 1000
log_interval: 10
save_interval: 200

# Runtime settings
# ----------------
num_workers: 0
seed: 1337
device: cuda
dtype: float32

data_parallel: false
